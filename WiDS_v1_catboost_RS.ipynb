{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle --upgrade\n",
    "# !pip install catboost\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkdir = '.../DATASCI-WiDS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training =  pd.read_csv(wkdir + \"/data/TrainingWiDS2021.csv\")\n",
    "data_dictionary = pd.read_csv(wkdir + \"/data/DataDictionaryWiDS2021.csv\")\n",
    "training = training.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "unlabeled = pd.read_csv(wkdir + \"/data/UnlabeledWiDS2021.csv\")\n",
    "unlabeled = unlabeled.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = dabl.detect_types(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = data_types[data_types['categorical']==True].index.tolist()\n",
    "print(\"**categorical features**\")\n",
    "print(categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = data_types[data_types['continuous']==True].index.tolist()\n",
    "print(\"**first 10 continuous features**\")\n",
    "print(continuous[:10])\n",
    "print(\"**total continuous features**\")\n",
    "print(len(continuous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless = data_types[data_types['useless']==True].index.tolist()\n",
    "print(\"**useless features**\")\n",
    "print(useless)\n",
    "print(\"**total useless features**\")\n",
    "print(len(useless))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test-validate split of labelled data for parameters tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**define target** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'diabetes_mellitus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**split data: train-validate-test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=random_state)\n",
    "for train_index, test_index in split.split(training, training[target]):\n",
    "    strat_train_set = training.loc[train_index]\n",
    "    strat_test_set = training.loc[test_index]\n",
    "training['test'] = np.where(training['encounter_id'].isin(strat_test_set['encounter_id']), True, False)\n",
    "non_test = training.loc[training['test'] == False]\n",
    "test = training.loc[training['test'] == True]\n",
    "\n",
    "# second split\n",
    "train, validate = train_test_split(non_test, test_size=0.2, stratify=non_test[target], random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train : ' + str(train.shape))\n",
    "print('test : ' + str(test.shape))\n",
    "print('validate : ' + str(validate.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**handle missing values by the split above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## fill NA of numerics with median value\n",
    "for col in continuous:\n",
    "    train[col].fillna(train[col].median(), inplace=True)\n",
    "    test[col].fillna(test[col].median(), inplace=True)\n",
    "    validate[col].fillna(validate.median(), inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill NAs of categoricals with most common values\n",
    "categorical_nas = ['ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source']\n",
    "train[categorical_nas] = train[categorical_nas].fillna(train.mode().iloc[0])\n",
    "test[categorical_nas] = test[categorical_nas].fillna(test.mode().iloc[0])\n",
    "validate[categorical_nas] = validate[categorical_nas].fillna(validate.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unique values')\n",
    "for col in categoricals:\n",
    "    print(col + ' : ' + str(train[col].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals.remove(target)\n",
    "categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous.remove('encounter_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = continuous + categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[model_features]\n",
    "y_train = train[target]\n",
    "X_test = test[model_features]\n",
    "y_test = test[target]\n",
    "X_validate = validate[model_features]\n",
    "y_validate = validate[target]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.07, 0.1, 0.2, 0.3],\n",
    "        'depth': [4, 5, 6, 7, 8, 9, 10],\n",
    "        'l2_leaf_reg': [3, 4, 5],\n",
    "        'iterations': [400, 500, 600, 700],\n",
    "        'early_stopping_rounds' : [30, 40, 50, 60],\n",
    "        'custom_metric':['Logloss', 'AUC', 'Precision', 'Recall', 'F1', 'BalancedAccuracy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = CatBoostClassifier()\n",
    "\n",
    "pool_ds = pd.concat([X_train, X_test])\n",
    "label_ds = pd.concat([y_train, y_test])\n",
    "rs_pool = Pool(data = pool_ds,\n",
    "              label = label_ds,\n",
    "              cat_features = categoricals)\n",
    "\n",
    "model.randomized_search(grid,\n",
    "                      rs_pool,\n",
    "                      y=None,\n",
    "                      cv=3,\n",
    "                      n_iter=10,\n",
    "                      partition_random_seed=0,\n",
    "                      calc_cv_statistics=True, \n",
    "                      search_by_train_test_split=True,\n",
    "                      refit=True, #refit best model\n",
    "                      shuffle=True, \n",
    "                      stratified=True, \n",
    "                      train_size=0.8, \n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best parms\n",
    "rs_best_params = model.get_params()\n",
    "rs_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_feat_imp(model):\n",
    "    feature_importance_df = pd.DataFrame(model.get_feature_importance(prettified=True))\n",
    "    plt.figure(figsize=(10, 30));\n",
    "    sns.barplot(x=\"Importances\", y=\"Feature Id\", data=feature_importance_df);\n",
    "    plt.title('CatBoost features importance:', fontsize=16, weight=\"bold\");\n",
    "\n",
    "plot_feat_imp(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model's performance on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/catboost/tutorials/blob/master/classification/classification_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "metrics.plot_roc_curve(model, X_validate, y_validate)\n",
    "plt.title('ROC curve catBoost RS model', fontsize=14, weight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(model.predict(X_validate[model_features]))\n",
    "y_true = y_validate\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'depth': 6,\n",
    "#  'od_wait': 50,\n",
    "#  'l2_leaf_reg': 4,\n",
    "#  'iterations': 700,\n",
    "#  'learning_rate': 0.05,\n",
    "#  'custom_metric': 'BalancedAccuracy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## retrain on all data\n",
    "pool_ds = pd.concat([X_train, X_test, X_validate])\n",
    "label_ds = pd.concat([y_train, y_test, y_validate])\n",
    "\n",
    "model = CatBoostClassifier(**rs_best_params)\n",
    "\n",
    "model.fit(pool_ds,\n",
    "          label_ds,\n",
    "          cat_features = categoricals,\n",
    "          plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill NA of numerics with median value\n",
    "for col in continuous:\n",
    "    unlabeled.fillna(unlabeled.median(), inplace=True)\n",
    "## fill NA of categoricals with mode    \n",
    "for col in categoricals:\n",
    "    unlabeled.fillna(unlabeled.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs = pd.DataFrame(model.predict_proba(unlabeled[model_features])[:, 1])\n",
    "predicted_labels = pd.DataFrame(model.predict(unlabeled[model_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = unlabeled['encounter_id'].to_frame()\n",
    "result[target] = predicted_probs\n",
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('.../submissions/submission_catboost_RS_180221.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c widsdatathon2021 -f '.../submission_catboost_RS_180221.csv' -m \"catboost RS submission 180221\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"code\"></form>''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}